<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Photogrammetry 3D Digitisation: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="../assets/styles.css">
<script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="manifest" href="../site.webmanifest">
<link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav incubator"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><abbr class="badge badge-light" title="This lesson is in the beta phase, which means that it is ready for teaching by instructors outside of the original author team." style="background-color: #001483; border-radius: 5px">
          <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#polishing-beta-stage" class="external-link alert-link" style="color: #FFF7F1">
            <i aria-hidden="true" class="icon" data-feather="alert-circle" style="border-radius: 5px"></i>
            Beta
          </a>
          <span class="visually-hidden">This lesson is in the beta phase, which means that it is ready for teaching by instructors outside of the original author team.</span>
        </abbr>
        
      </div>
    </div>
    <div class="selector-container">
      
      
      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='../aio.html';">Learner View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Photogrammetry 3D Digitisation
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="search button" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Photogrammetry 3D Digitisation
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
<input class="form-control me-2 searchbox" type="search" placeholder="Search" aria-label="Search"><button class="btn btn-outline-success tablet-search-button" type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="search button"></i>
        </button>
      </fieldset>
</form>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Photogrammetry 3D Digitisation
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../aio.html">Learner View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->
      
            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="introduction.html">1. Introduction</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="processing-overview.html">2. Processing overview</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="photogrammetry-software.html">3. Using photogrammetry software</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="additional-links.html">4. Additional Links</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width resources">
<a href="../instructor/aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">
            
            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-introduction"><p>Content from <a href="introduction.html">Introduction</a></p>
<hr>
<p>Last updated on 2024-03-26 |
        
        <a href="https://github.com/culturedigitalskills/2024-digitisation-photogrammetry/edit/main/episodes/introduction.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 90 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li><p>What is photogrammetry?</p></li>
<li><p>Where and when can we use photogrammetry?</p></li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li><p>Explains what is photogrammetry</p></li>
<li><p>Shows various scenarios where this technique can be applied to
capture real world objects and environments.</p></li>
</ul>
<!-- - Advantages and disadvantages for the use of this techniques.-->
</div>
</div>
</div>
</div>
</div>
<section id="definition-what"><h2 class="section-heading">Definition (What)<a class="anchor" aria-label="anchor" href="#definition-what"></a>
</h2>
<hr class="half-width">
<p>There are different terms to be aware of when referring to
photogrammetry. This term was coined for the first time by Prussian
architect <strong>Albrecht Meydenbauer</strong> and it refers to the act
of measuring the images to understand the 3d position of the represented
object or environment. You can read more about the history <a href="http://www.theulegium.de/fileadmin/user_upload/Texte/Meydenb.pdf" class="external-link"><strong>in
this article</strong></a> by Jörg Albertz. You can also find more
in-depth about the use of photogrammetry at the <a href="https://www.isprs.org/" class="external-link"><strong>International Society of
Photogrammetry and Remote Sensing</strong></a></p>
<table class="table">
<colgroup>
<col width="33%">
<col width="33%">
<col width="33%">
</colgroup>
<tbody>
<tr class="odd">
<td><img src="https://upload.wikimedia.org/wikipedia/commons/f/f3/Albrecht_Meydenbauer_%281834-1921%29.jpg" style="width:78.0%" alt="Albrecht Meydenbauer" class="figure"></td>
<td><img src="https://upload.wikimedia.org/wikipedia/commons/b/b3/Nakres_fotogrammetricke_kamery.jpg" style="width:83.0%" alt="Meydenbauer’s" class="figure"></td>
<td><img src="https://upload.wikimedia.org/wikipedia/commons/7/7d/Gelnhausen_Johanniterhof_81-015.jpg" alt="Holztor und der Johanniterhof" class="figure"></td>
</tr>
<tr class="even">
<td>Albrecht Meydenbauer (1834-1921) inconnu, photopile avant 1921,
Public domain, under <a href="https://creativecommons.org/licenses/by-sa/4.0" class="external-link">CC BY-SA 4.0</a>,
via <a href="https://commons.wikimedia.org/wiki/File:Albrecht_Meydenbauer_(1834-1921).jpg" class="external-link">Wikimedia
Commons</a>
</td>
<td>Meydenbauer’s camera developed in 1872, um 1900, Albrecht
Meydenbauer, Public domain, under <a href="https://creativecommons.org/licenses/by-sa/4.0" class="external-link">CC BY-SA 4.0</a>,
via <a href="https://commons.wikimedia.org/wiki/File:Nakres_fotogrammetricke_kamery.jpg" class="external-link">Wikimedia
Commons</a>
</td>
<td>Holztor und der Johanniterhof in Gelnhausen, um 1900, Albrecht
Meydenbauer, Public domain, under <a href="https://creativecommons.org/licenses/by-sa/4.0" class="external-link">CC BY-SA 4.0</a>,
via <a href="https://commons.wikimedia.org/wiki/File:Gelnhausen_Johanniterhof_81-015.jpg" class="external-link">Wikimedia
Commons</a>
</td>
</tr>
</tbody>
</table>
<p>Photogrammetry is the art, science, and technology of obtaining
spatial information about physical objects and environments through
processes of capturing, measuring and interpreting photographic 2d
images <a href="references">(Salma, 1980)</a>by means of <a href="https://en.wikipedia.org/wiki/Triangulation_(computer_vision)" class="external-link"><strong>triangulation
in computer vision</strong></a>. This process uses different algorithms
such as the <a href="https://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Triggs00.pdf" class="external-link"><strong>Bundle
Adjustment</strong></a> <em>“which refines simultaneously 3d coordinates
describing the geometry of the scene, the parameters of the relative
motion, and the optical characteristics of the camera(s) employed to
acquire the images, given a set of images depicting a number of 3D
points from different viewpoints”</em></p>
<table class="table">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<tbody>
<tr class="odd">
<td><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2c/TriangulationIdeal.svg/1280px-TriangulationIdeal.svg.png?20070822205517" alt="Triangulation Ideal" class="figure"></td>
<td><img src="https://upload.wikimedia.org/wikipedia/commons/c/c2/Fotogrammetria_digitale.jpg" alt="Comparison between analogue and digital" class="figure"></td>
</tr>
<tr class="even">
<td>Triangulation Ideal, Public domain, under <a href="https://creativecommons.org/licenses/by-sa/4.0" class="external-link">CC BY-SA 4.0</a>,
via <a href="https://commons.wikimedia.org/wiki/File:TriangulationIdeal.svg" class="external-link">Wikimedia
Commons</a>
</td>
<td>Comparison between analogue and digital stereometric cameras -
DaddabboA, Public domain, under <a href="https://creativecommons.org/licenses/by-sa/4.0" class="external-link">CC BY-SA 4.0</a>,
via <a href="https://commons.wikimedia.org/wiki/File:Confronto_analogic0_digital.jpg" class="external-link">Wikimedia
Commons</a>
</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/fbRFU3eKGoM?si=AM60aNOivlbLvv1F" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
</iframe>
<p><br><br></p>
<p>In reality, the reconstruction of the 3d scene is often referred to
as <a href="https://www.mathworks.com/help/vision/ug/structure-from-motion.html" class="external-link"><strong>SfM(Structure
from Motion)</strong></a>. For simplicity purposes in this workshop, we
are going to use the term “photogrammetry” to describe the whole process
of capturing and analyzing the images and reconstructing the 3d object
or environment.</p>
<table class="table">
<colgroup><col width="100%"></colgroup>
<tbody>
<tr class="odd">
<td><img src="https://upload.wikimedia.org/wikipedia/commons/4/42/Sede_da_Fazenda_do_Pinhal_%28159%29%2C_N.ELAC.jpg" style="width:100.0%" alt="Sede da Fazenda do Pinhal" class="figure"></td>
</tr>
<tr class="even">
<td>Sede da Fazenda do Pinhal (159), NELAC under <a href="https://creativecommons.org/licenses/by-sa/4.0" class="external-link">CC BY-SA 4.0</a>,
via <a href="https://en.wikipedia.org/wiki/File:Sede_da_Fazenda_do_Pinhal_(163),_N.ELAC.jpg" class="external-link">Wikimedia
Commons</a>
</td>
</tr>
</tbody>
</table>
<!--| Sede da Fazenda do Pinhal (159) &copy; NELAC under [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0), via [Wikimedia Commons 
| Sede da Fazenda do Pinhal (159) &copy; NELAC under [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0), via [Wikimedia Commons |--><p><br></p>
<blockquote>
<p>To record 3d data with the use of photogrammetry there are typical
steps to follow, which we will explore below. A more extensive workflow
and more guidelines can be found on the <a href="https://archaeologydataservice.ac.uk/help-guidance/guides-to-good-practice/data-collection-and-fieldwork/close-range-photogrammetry/data-collection-and-documentation/typical-steps-for-a-crp-project/" class="external-link"><strong>ADS
website</strong></a> and also at the <a href="https://www.geodetic.com/basics-of-photogrammetry/" class="external-link"><strong>Geodeditic
System Website</strong></a>.</p>
</blockquote>
</section><section id="contextualization-where-and-when"><h2 class="section-heading">Contextualization (Where and When)<a class="anchor" aria-label="anchor" href="#contextualization-where-and-when"></a>
</h2>
<hr class="half-width">
<p>There are multiple methods for the acquisition of 3d objects and
environments, one of which is photogrammetry. Within this method there
are different scenarios for its usage, later on in this workshop we will
practice with medium-small objects and different environments.</p>
<p><br></p>
<div class="section level3">
<h3 id="photogrammetry-techniques">
<strong>Photogrammetry techniques</strong><a class="anchor" aria-label="anchor" href="#photogrammetry-techniques"></a>
</h3>
<p>There are numerous photogrammetry applications. Different areas of
science and humanities are using this method to produce maps and 3d
models of the real world. It is however up to the experts in each field
of research, survey, and 3d production houses to choose and apply the
most appropriate technique.</p>
<p>The three main techniques are:</p>
<ul>
<li><strong>Space photogrammetry</strong></li>
<li><strong>Arial born photogrammetry</strong></li>
<li><strong>Terrestrial photogrammetry (long, medium and close
range)</strong></li>
</ul>
<p>The disciplines where these techniques are applied are:</p>
<p><br></p>
<ul>
<li><strong>Geo-science</strong></li>
</ul>
<p>Photogrammetry in geoscience is mostly used to produce <a href="https://archaeologydataservice.ac.uk/help-guidance/guides-to-good-practice/data-analysis-and-visualisation/gis/creating-and-using-gis-datasets/digital-elevation-models/" class="external-link"><strong>DEM
(Digital elevation models)</strong></a>, however, it can also be used to
study local terrain properties or part of a land by capturing the 3d
models of rocks, soil-type and vegetation, as well as studying their
conditions on a timescale. An example of this type of study can be found
in <a href="https://esurf.copernicus.org/preprints/esurf-2018-53/esurf-2018-53-manuscript-version3.pdf" class="external-link"><strong>this
article</strong></a> and <a href="https://pdf.sciencedirectassets.com/271791/1-s2.0-S0169555X12X00230/1-s2.0-S0169555X12004217/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHkaCXVzLWVhc3QtMSJHMEUCIF1YiilvObpxmTvHHmDoVJ75Y79snr6l9aUM9yZzNrM3AiEA7F5WaVfnWT9q5%2FgggFVSNJ1FijRmW2uWnqLNTXZ3NcUqswUIERAFGgwwNTkwMDM1NDY4NjUiDGKp4KNKUlQ8WrOLJCqQBaz68o4Y8LiFDt2CFA8Ly5D%2FyqQTAneRz9gXe0dI4n6VUynZLJDpjp3ix1vbtLZ3WW9dzi1NSNoBU7%2Fn5gRbew4N%2BS%2FrED6kvBr%2F7Oqls0f8GfPGAw06WAPmieYqS0Fl1A9jTJf7YAC1Wn02CnbfX7eo%2FqP6AHLie7qdameUp3dzNdzf3zeNEaxxTuiD%2Fwxo1SW5M8yCiKNToPLH%2FqIIcE7HiTY2%2BszDBB3YMdo%2BOTKyJetc9HAdVI8bqi7UpFu8o7cc9ES%2BOyngPAoXXQKOuV6k2WHBNtoxQlukcYD1kl54vpsXrA6908xR8JK%2FstXGT50oCVF2MkK0dQyPqlv5hAmqbrPQDn6DX90zuZHYxflK9LfUst29AWE6T8RLDEerTar6092bR27Elm6r7f%2BhnoJ2frTMbeP0VF0GMWxgCiBTkvDXZAIm2ByZCh4BB4f2%2F207HX%2FOjXheodEDhDSs%2Fix6UugjkvABXxxoiXhOFkKuxTXdUzG0xpjyDDGti4pHSYHbGfxwDILOq8ncUNXgvi185PmrQXJCRMUOVEc3pxVob%2BSzQug3xGm4GkgyhWBOGyd8jPtk6FOU1X80G8%2Fbq%2FpVvUTyIjuoFNUw47hHwGIVQMi1ear1QpRenpB2Eghv3l5z8Ep2YhIm4nhZeLjPa6hF6loSMMRabrVF2mJbRbIAX2auoHrpiv04e4tFrROmr%2BrndAZl%2FJDyZ03qK39ezIvNPtgCz9uO7gZRg37CfQ3NM7ek4pt4zYznZ%2BFanz%2FSC%2BccKGQ2qM1ERMSwqETMJiy5QzSIeFgMSzaYDP5D%2BpY9K3H%2BRkk2oD%2Bkb7Y5bYOdUIrA6Ibb4gbvm0ONxZCr2bqW2TFJzBONPhX1epTW4xfdMJfHxKwGOrEBB%2F4d2cZjr5d%2FvGS2wcYSuUDSwNTejfiDsoQjBY1%2FzcOKfIBhHXcYk%2FDio50wHQTkCdMFjB4pI9i%2BV8W%2Bb897Fu8x%2BXm%2BPLjEcrYqCrIMM54Va%2FaWDF7ofaOqT9ddG06VefelpHwhPveFIHniHxA7dNRW8o0M0NAxbn%2BtM2rLpUJQ3kpMmQ20hH20CFfp30Xh0IhP3HQv46JTE9zvqICWD5AEFMxTvwT3HckGCb79IgTL&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20231231T095114Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTYYYB7TB6F%2F20231231%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Signature=192fb9b454734f766543082407c5dab1274c24ba35226c064e0703d5b4e3d77a&amp;hash=40a582c434931007f377d9a7976913e561eaa82ff849cbe20208126291083e51&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S0169555X12004217&amp;tid=spdf-8eac46f4-41fe-4b5c-8e36-c57e93843a42&amp;sid=73fcd6aa6c07564ac318d5a13d9eee95bb8bgxrqb&amp;type=client&amp;tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&amp;ua=13125b5c065e5907525103&amp;rr=83e19f71de9c3750&amp;cc=it" class="external-link"><strong>this
article</strong></a></p>
<table class="table">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<tbody>
<tr class="odd">
<td><img src="https://upload.wikimedia.org/wikipedia/commons/f/f2/The_difference_between_Digital_Surface_Model_%28DSM%29_and_Digital_Terrain_Models_%28DTM%29_when_talking_about_Digital_Elevation_models_%28DEM%29.svg" alt="The difference between Digital Surface Model (DSM) and Digital Terrain Models (DTM) when talking about Digital Elevation models (DEM)" class="figure"></td>
<td><img src="https://upload.wikimedia.org/wikipedia/commons/1/1b/Digital_Elevation_Model_-_Red_Rocks_Amphitheater%2C_Colorado.jpg" style="width:100.0%" alt="Digital Elevation Model - Red Rocks Amphitheater, Colorado" class="figure"></td>
</tr>
<tr class="even">
<td>The difference between Digital Surface Model (DSM) and Digital
Terrain Models (DTM) when talking about Digital Elevation models (DEM),
Public domain, Arbeck, under <a href="https://creativecommons.org/licenses/by-sa/4.0" class="external-link">CC BY-SA 4.0</a>,
via <a href="https://commons.wikimedia.org/wiki/File:The_difference_between_Digital_Surface_Model_(DSM)_and_Digital_Terrain_Models_(DTM)_when_talking_about_Digital_Elevation_models_(DEM).svg" class="external-link">Wikimedia
Commons</a>
</td>
<td>Digital Elevation Model - Red Rocks Amphitheater, Colorado, Public
Domain, Stoermerjp, under <a href="https://creativecommons.org/licenses/by-sa/3.0" class="external-link">CC BY-SA 3.0</a>,
via <a href="https://commons.wikimedia.org/wiki/File:Digital_Elevation_Model_-_Red_Rocks_Amphitheater,_Colorado.jpg" class="external-link">Wikimedia
Commons</a>
</td>
</tr>
</tbody>
</table>
<p><br></p>
<ul>
<li><strong>Archaeology and Cultural Heritage</strong></li>
</ul>
<p>Photogrammetry in Archeology and Cultural Heritage is used for many
different purposes. It can be used every time a recording of a
three-dimensional shape or surface is required for scientific research,
archiving and publication.</p>
<blockquote>
<p>Although we have listed this as a separate discipline, archaeology
itself can be considered multidisciplinary. Therefore photogrammetry in
this area has many different uses. <a href="https://www.mdpi.com/2071-1050/13/9/5319" class="external-link"><strong>This
paper</strong></a> and <a href="https://historicengland.org.uk/images-books/publications/photogrammetric-applications-for-cultural-heritage/heag066-photogrammetric-applications-cultural-heritage/" class="external-link"><strong>this
guideline</strong></a> from <strong>Historic England</strong> can help
you to understand this tool under this domain. <a href="https://www.researchgate.net/profile/Predrag-Novakovic-2/publication/322096576_3D_Digital_Recording_of_Archaeological_Architectural_and_Artistic_Heritage/links/5a44bce80f7e9ba868a7d110/3D-Digital-Recording-of-Archaeological-Architectural-and-Artistic-Heritage.pdf?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoicHVibGljYXRpb24iLCJwcmV2aW91c1BhZ2UiOiJfZGlyZWN0In19" class="external-link"><strong>Here</strong></a>
you can find also a very good guide that explains the process and the
tools for 3d recording of Archaeological, Architectural and Artistic
Heritage.</p>
</blockquote>
<p>We can distinguish two main categories of photogrammetry in this
field, however the second category can be further divided into more
specific ones. In this workshop we will focus mainly on the second
category:</p>
<ul>
<li><p>Long-range Arial photography (and photogrammetry), which we
already introduced above in geo-science.</p></li>
<li>
<p>Close-range photogrammetry</p>
<ul>
<li><p>Long-distance, which includes 3d capturing of
<strong>terrains</strong>(to create DTMs), can be performed also on a
terrestrial level when the area of study is not too large, otherwise,
Arial-born techniques it will be preferable, such as the use of a drone
or other elevated point of capturing.</p></li>
<li><p>Medium-distance, which includes <strong>excavations</strong> and
<strong>buildings</strong> This type of photogrammetry</p></li>
</ul>
</li>
</ul>
<table class="table">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<tbody>
<tr class="odd">
<td><iframe width="560" height="315" title="Escavações Fórum Ammaia" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share src="https://sketchfab.com/models/c5d03b04499f44ccb43a67193b471d14/embed">
</iframe></td>
<td></td>
</tr>
<tr class="even">
<td>Escavações Fórum Ammaia, Fundacao Cidade De Ammaia, under <a href="http://www.ammaia.pt/" class="external-link">Fundacao Cidade De Ammaia</a>, via <a href="https://sketchfab.com/3d-models/escavacoes-forum-ammaia-c5d03b04499f44ccb43a67193b471d14" class="external-link">SketchFab</a>
</td>
<td></td>
</tr>
<tr class="odd">
<td><img src="https://upload.wikimedia.org/wikipedia/commons/5/56/Saint-Sulpice_Pointcloud_colored_coords.png" alt="Saint-Sulpice Pointcloud colored coords" class="figure"></td>
<td></td>
</tr>
<tr class="even">
<td>Saint-Sulpice Pointcloud colored coords, Richard Vock, under <a href="https://creativecommons.org/licenses/by-sa/4.0" class="external-link">CC BY-SA 4.0</a>,
via <a href="https://commons.wikimedia.org/wiki/File:Saint-Sulpice_Pointcloud_colored_coords.png" class="external-link">Wikimedia
Commons</a>
</td>
<td></td>
</tr>
</tbody>
</table>
<p><br></p>
<ul>
<li>Short-distance which includes large and medium objects such as
<strong>pieces of structures, pottery, sculptures, bones and other
artifacts</strong>
</li>
</ul>
<table class="table">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<tbody>
<tr class="odd">
<td><img src="https://upload.wikimedia.org/wikipedia/commons/5/5c/Sfm1.jpg" style="width:85.0%" alt="Sfm1" class="figure"></td>
<td><img src="https://upload.wikimedia.org/wikipedia/commons/e/e9/Wall_Painting.png" alt="Wall Painting" class="figure"></td>
</tr>
<tr class="even">
<td>Sfm1,Public Domain, Maiteng, under <a href="https://creativecommons.org/licenses/by-sa/4.0" class="external-link">CC BY-SA 4.0</a>,
via <a href="https://commons.wikimedia.org/wiki/File:Sfm1.jpg" class="external-link">Wikimedia
Commons</a>
</td>
<td>Wall Painting Photogrammetry Scan and made in 3dmax, Public Domain,
DanielNaseri, under <a href="https://creativecommons.org/licenses/by-sa/4.0" class="external-link">CC BY-SA 4.0</a>,
via <a href="https://commons.wikimedia.org/wiki/File:Wall_Painting.png" class="external-link">Wikimedia
Commons</a>
</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col width="33%">
<col width="33%">
<col width="33%">
</colgroup>
<tbody>
<tr class="odd">
<td><img src="https://data.d4science.org/shub/E_TGhlVFBIeFhkcWtzcE5KVFRVaXYyelJRdUk3YmtGRFByK2x5ZnhlUE9OK05LZU5NanUrSUtnSWptbVJLaWt6Ug==" style="width:75.0%" alt="Spring and Summer" class="figure"></td>
<td><img src="https://data.d4science.org/shub/E_dXdkL1VLYnFySzJ6d0puZVN0aDBCQktnUzY0TlNzdGNCM3FHZVg5enBkV1d3M1NDaUZ5dHJQY0NINU1MS0pWaA==" style="width:85.0%" alt="Spring and Summer" class="figure"></td>
<td><img src="https://data.d4science.org/shub/E_SG1ONWlMVFB3TW1YQkRZcXBVeDNXUlpzV1ZIYU9uWEY4OG5EblZnenNmRXdYeVY1SlBSQTdJZlNicFVzTXVTbA==" style="width:85.0%" alt="Spring and Summer" class="figure"></td>
</tr>
<tr class="even">
<td>
<strong>Photo</strong> of <a href="https://www.publicsculpturesofsussex.co.uk/object?id=184" class="external-link">“Spring
and Summer”</a> statues at Preston Park Brighton, DSVMC University of
Brighton, under <a href="https://culturedigitalskills.org/" class="external-link">DSVMC</a>,
via <a href="https://services.d4science.org/" class="external-link">D4Science</a>
</td>
<td>
<strong>Mesh</strong> of <a href="https://www.publicsculpturesofsussex.co.uk/object?id=184" class="external-link">“Spring
and Summer”</a> statues at Preston Park Brighton, DSVMC University of
Brighton, under <a href="https://culturedigitalskills.org/" class="external-link">DSVMC</a>,
via <a href="https://services.d4science.org/" class="external-link">D4Science</a>
</td>
<td>
<strong>Final Model</strong> <a href="https://www.publicsculpturesofsussex.co.uk/object?id=184" class="external-link">“Spring
and Summer”</a> statues at Preston Park Brighton, DSVMC University of
Brighton, under <a href="https://culturedigitalskills.org/" class="external-link">DSVMC</a>,
via <a href="https://services.d4science.org/" class="external-link">D4Science</a>
</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup><col width="100%"></colgroup>
<tbody>
<tr class="odd">
<td><iframe width="560" height="315" title="AMM_0029" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share src="https://sketchfab.com/models/3f26545258c74732b4fd84c79d3a924b/embed">
</iframe></td>
</tr>
<tr class="even">
<td>AMM_0029, Fundacao Cidade De Ammaia, under <a href="http://www.ammaia.pt/" class="external-link">Fundacao Cidade De Ammaia</a>, via <a href="https://sketchfab.com/3d-models/amm-0029-3f26545258c74732b4fd84c79d3a924b" class="external-link">SketchFab</a>
</td>
</tr>
</tbody>
</table>
<p><br></p>
<ul>
<li>Closeup-distance, which includes <strong>all small objects, pottery,
osteological or lithic pieces</strong>.</li>
</ul>
<table class="table">
<colgroup><col width="100%"></colgroup>
<tbody>
<tr class="odd">
<td><img src="https://upload.wikimedia.org/wikipedia/commons/9/92/Shell_in_real_%28left%29_and_Mesh_%28right%29_from_Meshroom_-_visualization.png" style="width:100.0%" alt="Shell in real (left) and Mesh (right) from Meshroom" class="figure"></td>
</tr>
<tr class="even">
<td>Visualization of a real shell and a 3D model from 120 images.,
Public Domain, Colin Kranz, under <a href="https://creativecommons.org/licenses/by-sa/4.0" class="external-link">CC BY-SA 4.0</a>,
via <a href="https://commons.wikimedia.org/wiki/File:Shell_in_real_(left)_and_Mesh_(right)_from_Meshroom_-_visualization.png" class="external-link">Wikimedia
Commons</a>
</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup><col width="100%"></colgroup>
<tbody>
<tr class="odd">
<td><iframe width="560" height="315" title="Taça Terra Sigillata." frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share src="https://sketchfab.com/models/32cf8d2e9aec4c2cbb0c71ad54b8a01b/embed">
</iframe></td>
</tr>
<tr class="even">
<td>Taça Terra Sigillata, Fundacao Cidade De Ammaia, under <a href="http://www.ammaia.pt/" class="external-link">Fundacao Cidade De Ammaia</a>, via <a href="https://sketchfab.com/3d-models/taca-terra-sigillata-32cf8d2e9aec4c2cbb0c71ad54b8a01b" class="external-link">SketchFab</a>
</td>
</tr>
</tbody>
</table>
<p><br></p>
<ul>
<li><strong>Surveying and construction</strong></li>
</ul>
<p>Photogrammetry in construction, civil survey and architecture is very
well established. Because the large amount of data that is usually
produced in this field is heavy on the process a <strong>Point
Cloud</strong> in a different format is used. This permits the
visualization of millions of points at the same time. All the points
have Cartesian coordinates in space and they can also contain RGB values
for color representation.</p>
<p>In this area of application, in fact, the final 3d mesh is only
produced if strictly necessary while the point cloud model is usually
used as a backdrop to reconstruct the more precise CAD model in a <a href="https://constructible.trimble.com/construction-industry/what-is-bim-building-information-modeling" class="external-link">BIM
environment</a>.</p>
<p>The most used software to visualize point clouds before importing
them into a more specific CAD software are <a href="https://www.meshlab.net/" class="external-link"><strong>Meshalb</strong></a> and <a href="https://www.danielgm.net/cc/" class="external-link"><strong>CloudCompare</strong></a>.</p>
<table class="table">
<colgroup><col width="100%"></colgroup>
<tbody>
<tr class="odd">
<td><img src="https://upload.wikimedia.org/wikipedia/commons/4/4b/Scan-to-BIM-ava.jpg" style="width:100.0%" alt="Scan-to-BIM-ava" class="figure"></td>
</tr>
<tr class="even">
<td>Scan to BIM is process to convert pointclouds, which are generated
by Laser scanning, to BIM model, Public Domain, Quynhphamnhat, under <a href="https://creativecommons.org/licenses/by-sa/4.0" class="external-link">CC BY-SA 4.0</a>,
via <a href="https://commons.wikimedia.org/wiki/File:Scan-to-BIM-ava.jpg" class="external-link">Wikimedia
Commons</a>
</td>
</tr>
</tbody>
</table>
<iframe width="560" height="315" src="https://www.youtube.com/embed/yXCkyuo8bcs?si=5om0ytc9ZMO_UrLy" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
</iframe>
<p><br></p>
<blockquote>
<p>The video above <a href="https://www.dronegenuity.com/point-clouds/" class="external-link"><strong>this
page</strong></a> explains more in-depth the origin and the use of a
point cloud.</p>
</blockquote>
<p><br></p>
<ul>
<li><strong>Film and Entertainment</strong></li>
</ul>
<p>In recent years, with the advent of powerful graphic cards and new
graphic engines, photogrammetry has started to be implemented in the
film and video games industry. Rather than manually building and
texturing real environments and characters, 3d companies have now
realized that capturing models directly from the real world has its own
advantages. One of these tools is <a href="https://www.capturingreality.com/" class="external-link"><strong>Reality
Capture</strong></a> which is able to capture 3d objects from your
mobile phone to import them into your game developing pipeline or any
other apps.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/MjIPC5Rm6ss?si=-XdA6z8nw-_nXpYj" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
</iframe>
<p><br><br></p>
<ul>
<li><strong>Forensic</strong></li>
</ul>
<p>In this field photogrammetry has an extensive usage One of the tools
mainly used is <a href="https://www.photomodeler.com/forensic-photogrammetry-case-study/" class="external-link">Photomodeler</a>
which has been one of the pioneer software in this discipline.</p>
<table class="table">
<colgroup><col width="100%"></colgroup>
<tbody>
<tr class="odd">
<td><img src="https://upload.wikimedia.org/wikipedia/commons/f/fe/SfM_PPT_GUI_vs_PHOTO.png" style="width:100.0%" alt="SfM PPT GUI vs PHOTO" class="figure"></td>
</tr>
<tr class="even">
<td>Real photo x photo scan with texture color x photo scan with simple
shader. Made with Python Photogrammetry Toolbox and rendered in Blender
with Cycles, Cicero Moraes, under <a href="https://creativecommons.org/licenses/by-sa/4.0" class="external-link">CC BY-SA 4.0</a>,
via <a href="https://commons.wikimedia.org/wiki/File:SfM_PPT_GUI_vs_PHOTO.png" class="external-link">Wikimedia
Commons</a>
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>You can read more about the use of photogrammetry in forensic surface
applications in <a href="https://open.bu.edu/ds2/stream/?#/documents/375440/page/1" class="external-link"><strong>this
paper</strong></a></p>
<p>In <a href="https://www.pix4d.com/blog/five-industries-that-use-photogrammetry/" class="external-link">this
article</a> you can find 5 industries that use photogrammetry for
different purposes.</p>
<p>We can conclude that on a technical level, the purpose of
photogrammetry is the reconstruction (or at least the 3d visualization)
of an object or a scene in 3 dimensions. However, this is not the only
technique to achieve it and there are <a href="https://archaeologydataservice.ac.uk/help-guidance/guides-to-good-practice/data-analysis-and-visualisation/3d-models/creating-3d-data/sources-and-types-of-3d-data/" class="external-link">various
sources of 3d data</a>.</p>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</section></section><section id="aio-processing-overview"><p>Content from <a href="processing-overview.html">Processing overview</a></p>
<hr>
<p>Last updated on 2024-03-26 |
        
        <a href="https://github.com/culturedigitalskills/2024-digitisation-photogrammetry/edit/main/episodes/processing-overview.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do you create 3d models for 3D digital preservation and
publication?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>To explain the techniques for creating 3d objects from 2d images
positioned at a different interval in space with specialized
software.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="processing-overview"><h2 class="section-heading">Processing overview<a class="anchor" aria-label="anchor" href="#processing-overview"></a>
</h2>
<hr class="half-width">
<p>Multiple 2d photographs can be used to generate <a href="https://en.wikipedia.org/wiki/Point_Cloud" class="external-link">point clouds</a> where
each point has now three-dimensional coordinates.</p>
<figure><img src="https://data.d4science.org/shub/E_aFlFV0paV3RQaGQwTkJrTGVpd0pVVktJdFpEeXh4b2gySU8yMjJTNGJybFc4Z2JNS2tqWm5raHRXK0U4VHFVRA==" alt="Dense Point Cloud example of a small object" class="figure mx-auto d-block"><div class="figcaption"><em>Dense Point Cloud example of a small
object</em></div>
</figure><p>These points can be further used to create 3d meshes by means of <a href="https://en.wikipedia.org/wiki/Mesh_generation" class="external-link">another type of
triangulation</a>.</p>
<figure><img src="https://data.d4science.org/shub/E_a0hoL2Y2dmZpREorYjNGTkx3QXBGcnZoQUd5NlhIVHQ0eStLZkVMd0hXN2RhckxRMDM5dG9ralpMaFFlSEs4cg==" alt="3d Mesh of a small object" class="figure mx-auto d-block"><div class="figcaption"><em>3d Mesh of a small object</em></div>
</figure><p>The mesh can then be <a href="https://en.wikipedia.org/wiki/Texture_mapping" class="external-link">texture mapped</a>
for the final realistic appearance of the studied subject.</p>
<figure><img src="https://data.d4science.org/shub/E_ZEp0UkZxbFFvdUVXN29QMmtqWldTdDlBRnBhZUdUcTBPZUhJbG44ZEFLOEsxM2R5dlBZaE1yUG9XVUZzcHZBVg==" alt="3d Mesh of a small object with texture" class="figure mx-auto d-block"><div class="figcaption"><em>3d Mesh of a small object with
texture</em></div>
</figure><iframe src="https://gltf-viewer.donmccurdy.com#kiosk=1&amp;model=https://data.d4science.org/shub/E_ZXp0WWx5S3JiVjE2RFc3WkVoMjhJSlUyUmpCWUFEQUdCSVlqamY2aC9zRUVGdWZLYWRVV0Vwem0xMHRiRkYwWQ==" style="width: 100%;" height="400px" frameborder="0">
</iframe>
<!--Underlying technology is more familiar
that we think! We can happily ignore 
the concepts and formulas used 
in the software. 

But it is useful to be aware of what it works.-->
<table class="table"><tbody></tbody></table>
<div class="section level3">
<h3 id="basic-steps-in-the-processing-phase">Basic steps in the processing phase<a class="anchor" aria-label="anchor" href="#basic-steps-in-the-processing-phase"></a>
</h3>
<p><strong>1. Feature detection</strong> (originally performed manually
but now performed automatically by the algorithm of the software)</p>
<p><strong>2. Feature matching</strong> (originally performed manually
but now performed automatically by the algorithm of the software)</p>
<p><strong>3. Structure reconstruction</strong> (performed automatically
by the algorithm of the software)</p>
</div>
<div class="section level3">
<h3 id="features-detection">Features detection<a class="anchor" aria-label="anchor" href="#features-detection"></a>
</h3>
<p>Features are “interest points” or “key points” in an image. The goal
of this step is to find points which are repeatable and distinctive.
Corners and other distinctive patterns in the image are obvious features
to consider.</p>
<div id="try-it-yourself." class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="try-it-yourself." class="callout-inner">
<h3 class="callout-title">Try it yourself.<a class="anchor" aria-label="anchor" href="#try-it-yourself."></a>
</h3>
<div class="callout-content">
<p>Open this image in Gimp or other photo editing software and try to
recognize 6 or more distinctive features.</p>
<p><a href="https://data.d4science.org/shub/E_VGNNb0R2VVltRmxaOHlhSXZnczIrTkZkL1ZUUXZlTElBLzBWTHUzenREdXZSb1RMcXNwdDBNS1Qwb2d3aWNnWQ==" class="external-link">Match-1</a></p>
<p>What points would you choose?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p><a href="https://data.d4science.org/shub/E_WW9zZUluVUxmVzJFRlpDcFV3UE5MeHVJNU96d25LWlJDdDhZZlJSQnpjcWptZVowRS9YcGxHWHZUN0RmLzVlSQ==" class="external-link">Here</a>
you can download an image of the possible solution. You will need to
zoom into the image to see the exact feature points.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="features-matching">Features matching<a class="anchor" aria-label="anchor" href="#features-matching"></a>
</h3>
<p>Find correspondences of features across different views. The goal of
this step is to detect (at least some of) correspondence between
features in two or more images.</p>
<div id="try-it-yourself.-1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="try-it-yourself.-1" class="callout-inner">
<h3 class="callout-title">Try it yourself.<a class="anchor" aria-label="anchor" href="#try-it-yourself.-1"></a>
</h3>
<div class="callout-content">
<p>Open this image in Gimp or other photo editing software and try to
recognize 6 or more features already found in the previous image.</p>
<p><a href="https://data.d4science.org/shub/E_NXBISUtZTnhDbHVGNHNxUXh0cEQzSGVldFVPMEtWWisyVU8xVmFCWWliTTNEQWIwNGx2VldUQ0xhWUZOMkk2SA==" class="external-link">Match-2</a></p>
<p>Do the features below correspond with each other?</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">Show me the solution</h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p><a href="https://data.d4science.org/shub/E_WFZSR0Z0Y29CTzNMNmVTdWNxelZqdFc2bkxOV3VuWU1nc0ViMVQ2MVU3RmtVMGZYd1NWclU4b24zWjB6R3VTUA==" class="external-link">Here</a>
you can download an image of the solution. You will need to zoom into
the image to see the exact feature points.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="structure-reconstruction">Structure reconstruction<a class="anchor" aria-label="anchor" href="#structure-reconstruction"></a>
</h3>
<!--Load all extracted features from an 
initial pair of images. Builds a 
projection of the points in 3D space by using the camera position.-->
<p>The software will recognize the features from all the loaded images.
Builds a projection of the points in 3D space by using the camera
position.</p>
<p>The scene is incrementally extended by adding new images and
triangulating new points. A much denser set of features is produced.</p>
<p>The output of this process is a “point cloud” or a <a href="#definition">collection of points</a>. The 3D model is created by
creating a <a href="#definition">triangular mesh</a>. The texture is
then mapped to the <a href="#definition">surface</a>.</p>
<figure><img src="https://data.d4science.org/shub/E_bU9MSEZaRGpOaGFJZ2hsL1dCWi85U0NZbUJiVDh5YlBlUmxmTGI3UE9ic1dvOEdkOGFpS3JnYmRrelYrY0JOaQ==" alt="Matching features in multiple images" class="figure mx-auto d-block"><div class="figcaption"><em>Matching features in multiple
images</em></div>
</figure><p>We can apply a mask to the whole sets of images so that the algorithm
does not have to calculate the points that are not interesting. In this
case when using turntables is recommended to shoot always one image
without the object.</p>
<figure><img src="https://data.d4science.org/shub/E_L3Y4dlE2Rm9ZVU1BcCtSaHFoS1A5UHZpUEpXYVdaK2tRNm9MOGdjT1Y0YXE3bkdvR2FTdU1MSlp1R3ozRVVwYg==" alt="Mask used in multiple images" class="figure mx-auto d-block"><div class="figcaption"><em>Mask used in multiple images</em></div>
</figure><figure><img src="https://data.d4science.org/shub/E_dUFhdW4vd2x0SVRNOWFjOWVjc1pwU2FyaFJXWlA2VnBzWjI1QnN5L3UvalMxYlVVSFhkMmEwb0FqTlkrdHZaMg==" alt="Reconstructed model from matching features in multiple images" class="figure mx-auto d-block"><div class="figcaption"><em>Reconstructed model from matching features
in multiple images</em></div>
</figure><!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</section></section><section id="aio-photogrammetry-software"><p>Content from <a href="photogrammetry-software.html">Using photogrammetry software</a></p>
<hr>
<p>Last updated on 2024-03-26 |
        
        <a href="https://github.com/culturedigitalskills/2024-digitisation-photogrammetry/edit/main/episodes/photogrammetry-software.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 60 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What software is available to create 3d models after image
acquisition?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Explains the techniques for using specific software for processing
the images and for creating 3d models.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="preparing-the-images"><h2 class="section-heading">Preparing the images<a class="anchor" aria-label="anchor" href="#preparing-the-images"></a>
</h2>
<hr class="half-width">
<p>Once the photographs have been acquired, the next step is to transfer
the images to a PC (refer to <a href="index.html#equipment">setup</a>
for specifications).</p>
<p>Please use the software we downloaded in the setup section <a href="https://www.3dflow.net" class="external-link">Raw Therapee</a>. With this free software,
you can convert the images from the raw file format to various other
formats. The raw file format of different cameras is probably already
the best file format you can use during the processing of the images in
the photogrammetry software because it retains the exif data, the most
accurate color range and the best resolution. However, not all the
photogrammetry software is able to read the different types of raw
formats of the different camera types. In this case, you will need to
use software such as Raw Therapy (which you can also use to re-organize
your files) to convert them into a more readable format. Usually, the
uncompressed Tiff or Tif file format is a good choice, because many
photogrammetry software can read it and it will retain good quality
information, including all the ones of the camera at the moment of
shooting.</p>
<p>Whatever file format you use it must be readable from the software
you are about to use for reconstructing the models and you must be sure
you choose a format that retains the Exif information within the file.
if you are not sure if your file has the information needed there are
lots of online tools that can provide such information. One example is
<a href="https://exifinfo.org/" class="external-link">ExifInfo.org</a>. Raw Therapee can also
provide this information on the info panel however you should always
check at least one of the images after exporting them.</p>
<p><br></p>
<blockquote>
<p>For this lesson the provided <a href="index.html#markdown-header-Examples-Data-Sets">examples data
sets</a> are already converted for you and, although it is better for
you to become familiar with batch converting software, at this stage you
will not need to take further actions after downloading them*</p>
</blockquote>
<!--
### Deleting the background 

If you wish to delete the 
background in the images, open one of the 
images that contain a large area of the 
background cloth in the image processing
software. 

Use the colour picker (circled in red) to select 
an area of the cloth. 

Click with the right mouse button on the 
background to select that area.

Go to "save as" and save it in the 
main project folder (NOT the images folder).

## Photogrammetry Software Workflow

The following instructions are specific
to 3DF Zephir.

Go to the workflow menu and choose *New Project*
 
### Import Images 

Browse to the folder that contains your 
images and click *Select Folder*.

Click *Create camera from each file*. 
The number of cameras that appear 
in the menu will depend on how
many images you have taken. 


Save the project in the project root folder. 

### Import Masks

Select the tools menu, 
go to import and select *Import Masks*.
 
 
Select *From background* in the Method drop down box.

Select *Replacement* in the *Operation* drop down box. 

In the *Filename template* select type in the 
name that you saved earlier in paint. 

Under tolerance, select a number from 30 to 50. 
The idea is that for each point in the image, 
it will compare it to the colour in our background 
mask image at the same point. If it is the same, 
it will not be included in the 3D model. 

The tolerance number is the amount that you 
expect the colour to vary to the background image. 
The larger the number, the larger it will allow 
a deviation from the colour to be masked out. 

Click *OK*. Then select the folder that contains the image.
 

Browse to the appropriate folder and 
click *Select Folder*.

Wait for the masks to be processed. 
The time to complete will depend on the number 
of images that you have taken.
 
 
Double click each image and look for any areas that 
have been masked out that shouldn’t have been. 
In this example, it has masked out the back of 
the model. 
Use either the rectangle or the loop tool 
(circled in red) to select the area.

 
Right click and choose *Subtract Selection*. 
This will remove the selection from the mask. 
Repeat this for all images.

Save the project so far.


### Align Photos

The next step is to align the photos. For
this, go to *Workflow* in the menu
and select *Align Photos*.
 
Select the options you want, 
but make sure the *Constrain features by mask* 
is selected. Then click *OK*.
 
 
Save the project so far. 

### Build dense cloud

Go to *Workflow* in the menu
and select *Build Dense Cloud*.


Choose the options you want and click *OK*.

Save the progress so far. 

### Build mesh

Go to *Workflow* in the menu
and select *Build Mesh*.

Choose your preferred options. 
Make sure *Source data* has *Dense cloud*
selected. 
Then click OK.
 

This process will produce a 3D model. 
The 3D model can be exported, 
or edited within the scene. 

### Build Texture

The final, optional step is to re-project 
the texture onto the 3D surface. 
This makes the photographic quality much better.


Go to *Workflow* in the menu
and select *Build Texture*.


Choose the following options. 
They are suitable for most models. 
Then click *OK*.
 
Now you will have a 3D model with the texture. -->
</section><section id="photogrammetry-software-workflow"><h2 class="section-heading">Photogrammetry Software Workflow<a class="anchor" aria-label="anchor" href="#photogrammetry-software-workflow"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="organizing-the-workspace">Organizing the workspace<a class="anchor" aria-label="anchor" href="#organizing-the-workspace"></a>
</h3>
<p>Using a suitable name which reflects your project, transfer all
images into a folder.</p>
<p>Good practices include:</p>
<pre><code><span>    <span class="va">ResourceIDifExistent_NameofObject_DateProcessedinFormatYY.MM.DD</span></span></code></pre>
<p>Within this folder, create another one named images. Copy the images
from the camera into the images folder.</p>
<p>The following instructions are specific to <a href="https://www.3dflow.net/3df-zephyr-photogrammetry-software/" class="external-link">3DF
Zephir</a>.</p>
<p>Go to the workflow menu and choose <strong>New Project</strong>, you
will be presented with a <em>“New project wizard window”</em>.</p>
<p>Choose the first box <em>Sparse</em> in order to go through the all
process manually. Click <strong>Next&gt;</strong> you will be presented
with the <em>“Photos selection page”</em> .</p>
</div>
<div class="section level3">
<h3 id="importing-images">Importing Images<a class="anchor" aria-label="anchor" href="#importing-images"></a>
</h3>
<ul>
<li>Browse to the folder that contains your images and click
<strong>Select Folder</strong> or Select your <strong>Single
Images</strong>. Click <strong>Next&gt;</strong>
</li>
<li>you will be presented with the <em>“Camera calibration page<em>”. If
you have a separate Exif file for calibrating the camera you can add it
here, and you can also manually calibrate your camera in the
</em>”Modify Calibration page”</em> otherwise go on and click
<strong>Next&gt;</strong>
</li>
</ul>
<figure><img src="https://data.d4science.org/shub/E_WHBodVMwdUZ5TXU3Z3h3MDhrQjBIMmFybkNGRXN6aEtqMUNuUWY2QlFKVmF5V1hxbzRFaDd6Q0ZIT0NsZ1BaNQ==" alt="Original photo" class="figure mx-auto d-block"><div class="figcaption"><em>Original photo</em></div>
</figure>
</div>
<div class="section level3">
<h3 id="importing-masks-optional">Importing Masks (optional)<a class="anchor" aria-label="anchor" href="#importing-masks-optional"></a>
</h3>
<p>In the <em>“Photos selection page”</em> there is an option to import
the mask, if selected a new option will be presented and a new tool
called <strong>Masquerade</strong> will be available before importing
the images. Within this tool (which is also available from the main
interface), it will be possible to generate a Mask to apply to all the
images. The tools are quite simple to use so that if you want to try to
apply a mask you can use a sample image provided in the sets of the
downloaded dataset as a first file.</p>
<figure><img src="https://data.d4science.org/shub/E_RFF0RkVickVCSmJCSHFtZm10MEYwNXFCN2xtY2JSVmY5MmxHVlo4a01WRUppcW9GK1Z0UzlXeHJXK1hJR3pwQQ==" alt="Original photo of the mask" class="figure mx-auto d-block"><div class="figcaption"><em>Original photo of the mask</em></div>
</figure>
</div>
<div class="section level3">
<h3 id="aligning-photos">Aligning Photos<a class="anchor" aria-label="anchor" href="#aligning-photos"></a>
</h3>
<p>The next step is to align the photos. For this:</p>
<ul>
<li>you will be presented with the <em>“Camera orientation page”</em>.
Keep the general setting and click <strong>Next&gt;</strong>
</li>
<li>you will be presented with the <em>“Start reconstruction”</em> page.
Click <strong>Run</strong>
</li>
<li>you will be presented with the <em>“Reconstruction Successful
page”</em>. Click <strong>Finish</strong>
</li>
<li>Save the project in the same <a href="#id_%20Create%20a%20folder">folder</a> created before.</li>
</ul>
<p><em>“Once the camera orientation phase has been completed, the sparse
point cloud will appear in the workspace as well as the oriented cameras
identified by blue pyramids.”</em> Now you can familiarize yourself with
the navigation of the 3d space and the interface. For example, go to
<strong>Scene-&gt; Bounding Box-&gt; Edit Bounding box</strong> and
limit the created sparse cloud within the bounding box. This will speed
up the process when creating the final mesh.</p>
<figure><img src="https://data.d4science.org/shub/E_dEtEY3RCZFYyVjMxMjNrOEcvYUxyUENieHpZZUdWc0g1TEVVVUtUTFhWTTRXZ0JON21tRkVKN2ZCREVjcFRxcA==" alt="Sparse Point Cloud" class="figure mx-auto d-block"><div class="figcaption"><em>Sparse Point Cloud</em></div>
</figure>
</div>
<div class="section level3">
<h3 id="build-a-dense-cloud-optional">Build a dense cloud (optional)<a class="anchor" aria-label="anchor" href="#build-a-dense-cloud-optional"></a>
</h3>
<p>The next step is to create a Dense PointCloud. For this:</p>
<ul>
<li>Go to <em>Workflow</em> in the menu and select <em>Advanced-&gt;
Dense Point Cloud Generation</em>.</li>
<li>you will be presented with the <em>“Dense Point Cloud Generation
wizard”</em>. <strong>Select All Cameras</strong> and click
<strong>Next&gt;</strong>
</li>
<li>you will be presented with the <em>“Dense Point Cloud Creation”</em>
page. Leave the general settings and click
<strong>Next&gt;</strong>
</li>
<li>you will be presented with the <em>“Start Densification”</em> page.
Click <strong>Run</strong>
</li>
<li>when finished you will be presented with the <em>“Dense Point Cloud
generation successful”</em> page, click <strong>Finish</strong>
</li>
<li>Save the project in the same <a href="#id_%20Create%20a%20folder">folder</a> created before.</li>
</ul>
<figure><img src="https://data.d4science.org/shub/E_enEwZ01YYXFVdVlrL3NGbXQrWkoxM2VOYk1sQkY3VVI1L014RUV5UjJsMGwvYWZvcU85endtdXpzU3A1OUpleA==" alt="Dense Point Cloud" class="figure mx-auto d-block"><div class="figcaption"><em>Dense Point Cloud</em></div>
</figure>
</div>
<div class="section level3">
<h3 id="cleaning-the-dense-cloud-optional">Cleaning the dense cloud (optional)<a class="anchor" aria-label="anchor" href="#cleaning-the-dense-cloud-optional"></a>
</h3>
<p>Before trying to create the final mesh we should delete all the
unwanted points that where generated within the bounding box. We could
do that by using the same bounding box to restrict even more the area
where the algorithm is going to be applied for the triangulation.
However in order to be accustom with the software interface, we will
delete all the unecessary points manually.</p>
<ul>
<li>Go to the <em>Editing panel</em> on your right and choose <strong>By
Hand</strong>. Choose <strong>Poly</strong> and
<strong>Remove</strong>.</li>
<li>Start selecting the points that you do not need and once selected
deleted them with the del key.</li>
<li>Once happy save the project in the same <a href="#id_%20Create%20a%20folder">folder</a> created before.</li>
</ul>
</div>
<div class="section level3">
<h3 id="building-the-mesh">Building the mesh<a class="anchor" aria-label="anchor" href="#building-the-mesh"></a>
</h3>
<p>The next step is to create a Dense PointCloud. For this:</p>
<ul>
<li>Go to <em>Workflow</em> in the menu and select <em>Advanced-&gt;
Mesh Extraction</em>
</li>
<li>you will be presented with the <em>“Mesh Generation wizard”</em>.
<strong>Drop Down</strong> the name of your dense point cloud,
<strong>Select All Cameras</strong> and click
<strong>Next&gt;</strong>
</li>
<li>you will be presented with the <em>“Surface Reconstruction”</em>
page. Leave the general settings and click
<strong>Next&gt;</strong>
</li>
<li>you will be presented with the <em>“Start Mesh Creation”</em> page.
Click <strong>Run</strong>
</li>
<li>when finished you will be presented with the <em>“Mesh Creation
successful”</em> page, click <strong>Finish</strong>. This process will
produce a 3D model.</li>
<li>Once happy save the project in the same <a href="#id_%20Create%20a%20folder">folder</a> created before.</li>
</ul>
<figure><img src="https://data.d4science.org/shub/E_eEIvTkZMYWdoM3pySDdjZUtjU0J1NGFya29vMDVyQ1ErQ0k5eHh1TVlXZkcxaVBUL21ydGlEa1NPeXU0UUhzZQ==" alt="High Resolution Mesh" class="figure mx-auto d-block"><div class="figcaption"><em>High Resolution Mesh</em></div>
</figure>
</div>
<div class="section level3">
<h3 id="building-the-texture">Building the Texture<a class="anchor" aria-label="anchor" href="#building-the-texture"></a>
</h3>
<p>The final step is to re-project the texture onto the 3D surface. For
this:</p>
<ul>
<li>Go to <em>Workflow</em> in the menu and select <em>Textured Mesh
Generation</em>
</li>
<li>you will be presented with the <em>“Textured Mesh Generation
wizard”</em>. <strong>Drop Down</strong> the name of your mesh,
<strong>Select All Cameras</strong> and click
<strong>Next&gt;</strong>
</li>
<li>you will be presented with the <em>“Texturing”</em> page. Leave the
general settings and click <strong>Next&gt;</strong>
</li>
<li>you will be presented with the <em>“Textured Mesh Generation
wizard”</em> page. Click <strong>Run</strong>
</li>
<li>when finished you will be presented with the <em>“Textured Mesh
Generation wizard result”</em> page, click <strong>Finish</strong>. Now
you will have a 3D model with the texture.</li>
<li>Save the project in the same <a href="#id_%20Create%20a%20folder">folder</a> created before.</li>
</ul>
<figure><img src="https://data.d4science.org/shub/E_R21uT3hnMGRjeGZ0WHVZUkgwTW9FLzFTYzJIaWYvVGY4RWltQ1ZkZmRiZTlndExkMEtPdGRsQll3N0UzZnBVbw==" alt="High Resolution Mesh Texture" class="figure mx-auto d-block"><div class="figcaption"><em>High Resolution Mesh Texture</em></div>
</figure>
</div>
<div class="section level3">
<h3 id="exporting-the-mesh-with-textures-for-high-res-visualization">Exporting the mesh with textures for High-Res visualization<a class="anchor" aria-label="anchor" href="#exporting-the-mesh-with-textures-for-high-res-visualization"></a>
</h3>
<p>At this point, we need to export a high-resolution mesh for different
purposes. For this:</p>
<ul>
<li>Go to <em>Export</em> in the menu and select <em>Export Textured
Mesh</em>. <strong>Drop Down</strong> the name of your mesh,
<strong>Drop Down</strong> your preferred format and click
<strong>Export</strong>
</li>
<li>create another folder called <em>“Exports”</em> within the same
folder of the images and save the model in this folder.</li>
</ul>
<p><img src="https://data.d4science.org/shub/E_Zk92OG5TUEN5ZGx1ais1WS80UWdVVEZORGRDKzl1YjNLR2syMWZYY3JFcTBBVGhQTSs5MjdFZTI4NVR3U2p1ZQ==" alt="https://data.d4science.org/shub/E_Zk92OG5TUEN5ZGx1ais1WS80UWdVVEZORGRDKzl1YjNLR2syMWZYY3JFcTBBVGhQTSs5MjdFZTI4NVR3U2p1ZQ==" class="figure"><em>High
Resolution Mesh Textured</em></p>
</div>
<div class="section level3">
<h3 id="exporting-the-mesh-with-textures-for-online-publishing">Exporting the mesh with textures for online publishing<a class="anchor" aria-label="anchor" href="#exporting-the-mesh-with-textures-for-online-publishing"></a>
</h3>
<p>At this point, we need to export the model at a lower resolution mesh
for online publishing. For this:</p>
<ul>
<li>Select your textured mesh in the right window <em>“Textured
Meshes”</em> <strong>Right Click</strong> on it and select
<strong>Clone</strong>. A copy of your mesh will be created.</li>
<li>Go to <em>Tools</em> in the menu and select <em>Mesh Filters-&gt;
Decimatiom</em>. You will be presented with the <em>“Mesh
decimation”</em> small window. <strong>Drop Down</strong> the name of
your second mesh, select <em>preserve boundaries</em> and <em>Apply
Filter</em>
</li>
</ul>
<p>At this point, we need to regenerate the texture for the
lower-resolution mesh. To do so we need to repeat the process above:</p>
<ul>
<li>Go to <em>Workflow</em> in the menu and select <em>Textured Mesh
Generation</em>
</li>
<li>you will be presented with the <em>“Textured Mesh Generation
wizard”</em>. <strong>Drop Down</strong> the name of your new mesh,
<strong>Select All Cameras</strong> and click
<strong>Next&gt;</strong>
</li>
<li>you will be presented with the <em>“Texturing”</em> page. Leave the
general settings and click <strong>Next&gt;</strong>
</li>
<li>you will be presented with the <em>“Textured Mesh Generation
wizard”</em> page. Click <strong>Run</strong>
</li>
<li>when finished you will be presented with the <em>“Textured Mesh
Generation wizard result”</em> page, click <strong>Finish</strong>. Now
you will have the new low-resolution 3D model with the texture.</li>
<li>Save the project in the same <a href="#id_%20Create%20a%20folder">folder</a> created before.</li>
<li>Go to <em>Export</em> in the menu and select <em>Export Textured
Mesh</em>. <strong>Drop Down</strong> the name of your second mesh,
<strong>Drop Down</strong> the format <strong><em>.glb</em></strong> or
<strong><em>.gltf</em></strong> and click <strong>Export</strong>
</li>
<li>create another folder called <em>“Exports”</em> within the same
folder of the images and save the model in this folder.</li>
</ul>
<iframe src="https://gltf-viewer.donmccurdy.com#kiosk=1&amp;model=https://data.d4science.org/shub/E_azJzMVp6MENORnRUd0FEdElCa3g5WVBIdEQ5cldBUlJwOHkyYjRITHpTYmVUcFdIUDc1VzRhWTFGdWc5SytNVA==" style="width: 100%;" height="400px" bgcolor="#dbdbdb" frameborder="0">
</iframe>
<p><br><br></p>
</div>
<div class="section level3">
<h3 id="adding-real-world-scale">Adding real-world scale<a class="anchor" aria-label="anchor" href="#adding-real-world-scale"></a>
</h3>
<p><img src=".././fig/HorseMatch1Cut.jpg" alt="Real World Scale" class="figure"><em>High
Resolution Mesh Textured</em></p>
<p>A very good practice, although it can also be achieved in a later
stage by measuring parts of the model, is to add a real world scale
within the working environment. .</p>
<p>This is useful for two reasons: - Scaling the object to real
measurement - Make measurements of objects or environments</p>
<p>After including a <a href=".././files/Photogrammetric_scale_noncoded_markers_plus_small.pdf">small</a>
or <a href=".././files/photogrammetric_scale_noncoded_markers_medium.pdf">larger</a>
printed scale reference, the best way to achieve this would be to use
Control Points. However this is only available on the non-free version
of 3dZephyr.</p>
<p>Steps to add real a scale within the model:</p>
<ul>
<li>print the scale and make sure that the measurements are correct
(when printing go to the printer settings and use 100% real size without
adapting the image to the size of the paper)</li>
<li>attach the printed sheet to an hard surface such as a base or a
turntable and make sure it does not have any bulges.</li>
<li>at this point you have two options:
<ul>
<li>when using a turntable if you attach the scale to the object and to
the turntable, the scale will be part of the 3D Model and will not be
used as a mask.</li>
<li>when not using a turntable if you attach the scale to the object it
will be part of the object and cannot be used as a mask while if you do
not attach it to the object you can also use it as a musk.</li>
</ul>
</li>
</ul>
<p><br></p>
</div>
<div class="section level3">
<h3 id="final-remarks">Final Remarks<a class="anchor" aria-label="anchor" href="#final-remarks"></a>
</h3>
<p>During the whole process, you will encounter more options and
settings than the ones described above. You can find a piece of more
complete and technical advice in <a href="https://www.3dflow.net/zephyr-doc/en/Extractingadensepointcloud.html" class="external-link">this
document</a>.</p>
<p>Or if you prefer it as a PDF file you can find it <a href="https://3df-eu.fra1.digitaloceanspaces.com/zephyr-doc/3DF%20Zephyr%20Manual%207.500%20English.pdf" class="external-link">here</a></p>
<p>As well as a series of video tutorials on <a href="https://www.3dflow.net/technology/documents/3df-zephyr-tutorials/" class="external-link">this
page</a>.</p>
<p>You can also find advice and specific topic help in the official <a href="https://www.3dflow.net/forums/" class="external-link">forum</a> of the software.</p>
<p>Finally, you can also join the <a href="https://discord.com/invite/3HMUKff" class="external-link">Discord Channel</a> if you
prefer.</p>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</section></section><section id="aio-additional-links"><p>Content from <a href="additional-links.html">Additional Links</a></p>
<hr>
<p>Last updated on 2024-03-26 |
        
        <a href="https://github.com/culturedigitalskills/2024-digitisation-photogrammetry/edit/main/episodes/additional-links.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<section id="additional-links"><h2 class="section-heading">Additional Links<a class="anchor" aria-label="anchor" href="#additional-links"></a>
</h2>
<hr class="half-width">
<p><br></p>
<div class="section level3">
<h3 id="theory">Theory<a class="anchor" aria-label="anchor" href="#theory"></a>
</h3>
<p>Image theory</p>
<ul>
<li><a href="https://www.cambridgeincolour.com/" class="external-link">Cambridge in
Color</a></li>
<li>
<a href="http://cs.brown.edu/courses/cs143/" class="external-link">Images and content from
James Hays, Computer Vision module @ Brown University</a> <!--
-	[Comparison of methods](http://www.stporter.com/wp- content/uploads/2016/04/A_Comparison_of_Methods_for_Creating_3D.pdf)
-	[Tips and Tricks](http://www.agisoft.com/support/tips-tricks/)-->
</li>
</ul>
<p>Photogrammetry</p>
<ul>
<li><a href="https://culturalheritageimaging.org/Technologies/Photogrammetry/" class="external-link">CHI</a></li>
<li><a href="https://archaeologydataservice.ac.uk/help-guidance/guides-to-good-practice/data-collection-and-fieldwork/close-range-photogrammetry/data-collection-and-documentation/typical-steps-for-a-crp-project/" class="external-link">ADS</a></li>
<li><a href="https://blog.sketchfab.com/how-to-set-up-a-successful-photogrammetry-project/" class="external-link">Tips
for setup</a></li>
<li><a href="http://www.tested.com/art/makers/460142-art-photogrammetry-how-take-your-%20photos/" class="external-link">Tips
for taking photos</a></li>
</ul>
</div>
<div class="section level3">
<h3 id="principles-and-guidelines">Principles and Guidelines<a class="anchor" aria-label="anchor" href="#principles-and-guidelines"></a>
</h3>
<ul>
<li><a href="https://digital-strategy.ec.europa.eu/en/library/basic-principles-and-tips-3d-digitisation-cultural-heritage" class="external-link">Basic
principles and tips for 3D digitisation of cultural heritage -European
Commission</a></li>
<li><a href="https://carare.gitbook.io/share-3d-guidelines/" class="external-link">Share 3D
Carare</a></li>
</ul>
</div>
<div class="section level3">
<h3 id="other-tutorials">Other tutorials<a class="anchor" aria-label="anchor" href="#other-tutorials"></a>
</h3>
<ul>
<li><a href="https://historicengland.org.uk/images-books/publications/photogrammetric-applications-for-cultural-heritage/heag066-photogrammetric-applications-cultural-heritage/" class="external-link">Historic
England’s Photogrammetry tutorial</a></li>
<li><a href="https://github.com/alicevision/meshroom/wiki/Tutorials" class="external-link">Alicevision</a></li>
</ul>
</div>
<div class="section level3">
<h3 id="tools-and-software">Tools and software<a class="anchor" aria-label="anchor" href="#tools-and-software"></a>
</h3>
<ul>
<li><a href="https://exifinfo.org/" class="external-link">Exif checker</a></li>
<li><a href="https://archaeologydataservice.ac.uk/about/projects/ads-3d-viewer/" class="external-link">ADS
3D viewer</a></li>
<li><a href="https://alicevision.org/#meshroom" class="external-link">Meshroom</a></li>
<li><a href="https://www.agisoft.com/" class="external-link">Metashape</a></li>
</ul>
<!--

### Additional Links

-	[Images and content from James Hays, Computer Vision module @ Brown University](http://cs.brown.edu/courses/cs143/)
-	[Comparison of methods](http://www.stporter.com/wp- content/uploads/2016/04/A_Comparison_of_Methods_for_Creating_3D.pdf)
-	[Tips and Tricks](http://www.agisoft.com/support/tips-tricks/)
-	[Tips for setup](https://blog.sketchfab.com/how-to-set-up-a-successful-photogrammetry-project/)
-	[Tips for taking photos](http://www.tested.com/art/makers/460142-art-photogrammetry-how-take-your- photos/)

--><!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://github.com/culturedigitalskills/2024-digitisation-photogrammetry/edit/main/README.md" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://github.com/culturedigitalskills/2024-digitisation-photogrammetry/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/culturedigitalskills/2024-digitisation-photogrammetry/" class="external-link">Source</a></p>
				<p><a href="https://github.com/culturedigitalskills/2024-digitisation-photogrammetry/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:K.Rodriguez@brighton.ac.uk">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.3" class="external-link">sandpaper (0.16.3)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.4" class="external-link">pegboard (0.7.4)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.1" class="external-link">varnish (1.0.1)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://culturedigitalskills.github.io/2024-digitisation-photogrammetry/instructor/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "photogrammetry, digitisation, data, lesson, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://culturedigitalskills.github.io/2024-digitisation-photogrammetry/instructor/aio.html",
  "identifier": "https://culturedigitalskills.github.io/2024-digitisation-photogrammetry/instructor/aio.html",
  "dateCreated": "2023-11-29",
  "dateModified": "2024-03-26",
  "datePublished": "2024-03-26"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo
    2022-11-07: we have gotten a notification that we have an overage for our
    tracking and I'm pretty sure this has to do with Workbench usage.
    Considering that I am not _currently_ using this tracking because I do not
    yet know how to access the data, I am turning this off for now.
  <script>
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
    _paq.push(["setDomains", ["*.preview.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
    _paq.push(["setDoNotTrack", true]);
    _paq.push(["disableCookies"]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
          var u="https://carpentries.matomo.cloud/";
          _paq.push(['setTrackerUrl', u+'matomo.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.async=true; g.src='https://cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
  </script>
  End Matomo Code -->
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

